{
    "contents" : "---\ntitle: \"Титаник. Модель прогнозирования вероятности выжить при крушении.\"\nauthor: \"Морозов Глеб\"\ndate: \"10 августа 2015 г.\"\noutput: \n  html_document: \n    keep_md: yes\n---\n\nДанная работа описывает мою попытку создать модель для предсказания выживших пассажиров \"Титаника\". Основная задача - тренировка в использовании инструментов применяемых в Data Science для анализа данных и презентации результатов исследования. Основное внимание уделено исследовательскому анализу(exploratory research) и работе по созданию и выбору предикторов(feature engineering).  Модель создаётся в рамках соревнования [Titanic: Machine Learning from Disaster](https://www.kaggle.com/c/titanic) проходящего на сайте [Kaggle](https://www.kaggle.com).\n\nВ своей работе я буду использовать язык \"R\".\n\n### Предпосылки для создания модели\nЕсли доверять [Википедии](https://ru.wikipedia.org/wiki/%D0%A2%D0%B8%D1%82%D0%B0%D0%BD%D0%B8%D0%BA), то Титаник столкнулся с айсбергом в 11:40 вечера корабельного времени, когда подавляющее болшинство пассажиров и корабельной команды находились в своих каютах. Соответственно, расположение кают, возможно, имело влияние на вероятность выжить, т.к. пассажиры нижних палуб, во-первых, позднее узнали о столкновении и, соответственно, имели меньше времени добраться до верхней палубы. И, во-вторых, им, естественно, было дольше выбираться из помещений корабля. Ниже изображены схемы Титаника с указанием палуб и помещений.\n![Схема Титаника с указанием некоторых элементов](figures/Titanik1.png)\n![Схема палуб Титаника](figures/Titanic_palyb.jpeg)\n\nТитаник являлся британским кораблем, а согласно законам Британии на корабле должно было быть число шлюпок, соответствующее водоизмещению судна, а не пассажировместимости. Титаник формально соответствовал этим требованиям и имел 20 шлюпок (14 со вместимостью 65 человек, 2 — 40 человек, 4 — 47 человек), которые были рассчитаны на погрузку 1178 человек, всего же на Титанике было 2208 человек. Таким образом, зная, что шлюпок на всех не хватит, капитан Титаника Смит отдал приказ брать на шлюпки только женщин и детей. Однако члены команды не всегда следовали ему.\n\n### Получение данных\nKaggle предоставляет данные в виде двух файлов в формате csv:\n\n- [`train.csv`](https://www.kaggle.com/c/titanic/download/train.csv) (содержит выборку пассажиров с известным исходом, т.е. выжил или нет)\n- [`test.csv`](https://www.kaggle.com/c/titanic/download/test.csv)  (содержит другую выборку пассажиров без зависимой переменной)\n\nДля получения данных в R я использую функцию `read_csv` из пакета `readr`. В сравнении с базовыми функциями данный пакет предоставляет ряд преимуществ, в частности: более высокую скорость и понятные названия параметров.\n\n```{r message=FALSE} \nrequire(readr)\ndata_train <- read_csv(\"train.csv\")\ndata_test <- read_csv(\"test.csv\")\n```\nПосмотрим, что у нас получилось:\n\n```{r}\nstr(data_train)\n```\n\n\n### Анализ данных\nИсследовательский анализ данных, как я считаю, является одной из наиболее важных частей работы Data Scientist's, т.к., кроме непосредственно преобразования \"сырых\" данных в готовые для создания модели, часто во время этого процесса можно увидеть скрытые зависимости, благодаря использованию которых и получаются наиболее точные модели.\n\nДля начала посмотрим на отсутствующие данные. В предоставленных данных часть отсутствующей информации была отмечена символом `NA` и при загрузке были по умолчанию преобразованы в особый символ `NA`. Но среди символьных переменных много пассажиров с пропущенными переменными, которые не были отмечены. Проверим их наличие используя возможности пакетов `magrittr` и `dplyr`\n\n```{r message=FALSE}\nrequire(magrittr)\nrequire(dplyr)\ndata_train %>% select(Name, Sex, Ticket, Cabin, Embarked) %>% apply(., 2, function(column) sum(column == \"\"))\n```\n\nЗаменим пропуски на `NA`, используя функцию `recode` из пакета `car`\n\n```{r message=FALSE}\nrequire(car)\ndata_train$Cabin <- recode(data_train$Cabin, \"'' = NA\")\ndata_train$Embarked <- recode(data_train$Embarked, \"'' = NA\")\n```\n\nДля графического представления  удобно использовать функцию `missmap` из пакета для работы с отсутствующими данными `Amelia`.\n\n```{r message=FALSE, warning=F}\nrequire(colorspace)\ncolors_A <- sequential_hcl(2)\nrequire(Amelia)\nmissmap(data_train, col = colors_A, legend=FALSE)\n```\n\nТаким образом пропущенно около 20% данных в переменной `Age` и почти 80% в `Cabin`. И если с возрастом пассажиров можно провести обоснованное замещение пропущенных значений, в связи с небольшой их долей, то с каютами маловероятно что-то получится сделать, т.к. пропущенных значений существенно больше нежели заполненных. Пропущенные значения в признаке `Embarked` \n\nК пропущенным значениям мы вернёмся позднее, а пока посмотрим какую информацию можно извлечь из тех данных, которые мы имеем. Напоминаю, что основная задача - определить переменные, влияющие на вероятность выжить при крушении Титаника. Попробуем получить начальные представления об этих зависимостях с помощью простых графиков. \n\n```{r message=FALSE, warning=F, fig.width= 9, fig.height= 10} \n## Для создания графиков в этом исследовании я буду стараться использовать пакет 'ggplot2'\nrequire(ggplot2)\nrequire(gridExtra)\ndata_train %<>% transform(., Survived = as.factor(Survived),\n                          Pclass = as.factor(Pclass), \n                          Sex = as.factor(Sex),\n                          Embarked = as.factor(Embarked),\n                          SibSp = as.numeric(SibSp))\ncolours <- rainbow_hcl(4, start = 30, end = 300)\n\nggbar <- ggplot(data_train) + geom_bar(stat = \"bin\", width=.6, fill= colours[3], colour=\"black\") +\n        guides(fill=FALSE) + ylab(NULL)\ng1 <- ggbar + aes(x = factor(Survived, labels = c(\"Погиб\", \"Выжил\"))) + \n        ggtitle(\"Распределение погибших\\n и спасшихся пассажиров\") + xlab(NULL)\ng2 <- ggbar + aes(x = factor(Pclass, labels = c(\"Первый\", \"Второй\", \"Третий\"))) + \n        ggtitle(\"Распределение пассажиров\\n по классам обслуживания\") + xlab(NULL)\ng3 <- ggbar + aes(x = factor(Sex, labels = c(\"Женщина\", \"Мужчина\"))) + \n        ggtitle(\"Распределение пассажиров между полами\") + xlab(NULL)\ng4 <- ggbar + aes(x = as.factor(SibSp)) + \n        ggtitle(\"Распределение пассажиров по сумме\\n 'супруг + братья и сёстры на борту корабля'\") + \n        xlab(NULL)\ng5 <- ggbar + aes(x = as.factor(Parch)) + \n        ggtitle(\"Распределение пассажиров по сумме\\n 'родители + дети на борту'\") + xlab(NULL)\ng6 <- ggbar + aes(x = factor(Embarked, labels = c(\"Cherbourg\", \"Queenstown\", \"Southampton\"))) +\n        ggtitle(\"Распределение пассажиров\\n по пункту отправления\") + \n        xlab(NULL)\n\ngghist <- ggplot(data_train) + geom_histogram(fill= colours[4]) + guides(fill=FALSE) + ylab(NULL)\ng7 <- gghist + aes(x = Age) + xlab(NULL) + ggtitle(\"Распределение пассажиров по возрастам\")\ng8 <- gghist + aes(x = Fare) + xlab(NULL) + ggtitle(\"Распределение пассажиров\\n по стоимости билетов\") \ngrid.arrange(g1, g2, g3, g4, g5, g6, g7, g8, ncol = 2, nrow=4)\n```\n\nУже можно делать первые выводы:\n\n- больше пассажиров погибло чем спаслось\n- подавляющее большинство пассажиров находилось в каютах третьего класса\n- мужчин было больше чем женщин\nВ целом, уже можно сказать, что основными факторами модели будет пол пассажира (вспомним приказ капитана, про который я писал ранее) и расположение каюты.\n\nНенадолго вернёмся к пропущенным значениям. Из графика `Распределение пассажиров по пункту отправления` очевидно, что большинство пассажиров отправлялось из `Southampton`, соответственно можно спокойно заменить 2 `NA` этим значением\n\n```{r}\ndata_train$Embarked[is.na(data_train$Embarked)] <- \"S\"\n```\n\nТеперь подробнее посмотрим на взаимоотношения между вероятностью выжить и другими факторами. Следующий график подтверждает теорию, что чем выше класс каюты пассажира - тем больше шансы выжить. (Под \"выше\"\" я имею ввиду обратный порядок, т.к. первый класс выше чем второй и, тем более, третий.)\n\n```{r fig.width= 9, fig.height= 4}\nggbar <- ggplot(data_train) + geom_bar(stat = \"bin\", width=.6)\nggbar + aes(x = factor(Pclass, labels = c(\"Первый\", \"Второй\", \"Третий\")),\n            fill = factor(Survived, labels = c(\"Погиб\", \"Выжил\"))) + \n        scale_fill_manual (values=colours[]) +\n        guides(fill=guide_legend(title=NULL)) + \n        ylab(NULL) + xlab(\"Класс каюты\")\n```\n\nСравним шансы выжить у мужчин и женщин. Данные подтверждают теорию, высказанную ранее.\n\n```{r fig.width= 9, fig.height= 4}\nggbar + aes(x = factor(Sex, labels = c(\"Женщина\", \"Мужчина\")),\n            fill = factor(Survived, labels = c(\"Погиб\", \"Выжил\"))) +\n        scale_fill_manual (values=colours[]) +\n        guides(fill=guide_legend(title=NULL)) + \n        ylab(NULL) + xlab(\"Пол пассажира\")\n```\n\nТеперь взглянем на шансы выжить у пассажиров из различных портов отправления.\n```{r fig.width= 9, fig.height= 4}\nggbar + aes(x = factor(Embarked, labels = c(\"Cherbourg\", \"Queenstown\", \"Southampton\")),\n            fill = factor(Survived, labels = c(\"Погиб\", \"Выжил\"))) +\n        scale_fill_manual (values=colours[]) +\n        guides(fill=guide_legend(title=NULL)) + \n        ylab(NULL) + xlab(\"Порт отправления\")\n```\n\nВроде бы просматривается какая-то связь, но я считаю, что это скорее связано с распределением пассажиров разных классов между этими портами, что и подтверждает следующий график.\n```{r fig.width= 9, fig.height= 4}\nggbar + aes(x = factor(Embarked, labels = c(\"Cherbourg\", \"Queenstown\", \"Southampton\")),\n            fill = factor(Pclass, labels = c(\"Первый\", \"Второй\", \"Третий\"))) +\n        scale_fill_manual (values=colours[]) +\n        guides(fill=guide_legend(title=\"Класс каюты\")) + \n        ylab(NULL) + xlab(\"Порт отправления\")\n```\n\nТакже можно проверить гипотезу, что выживают более молодые, т.к. они быстрее двигаются, лучше плавают и т.д.\n\n```{r fig.width= 9, fig.height= 4, warning=F}\nggplot(data_train, aes(x = factor(Survived, labels = c(\"Погиб\", \"Выжил\")), \n                       y = Age, fill = factor(Survived, labels = c(\"Погиб\", \"Выжил\")))) +\n        geom_boxplot() + scale_fill_manual (values=colours[]) +\n        guides(fill=guide_legend(title=NULL)) + \n        ylab(NULL) + xlab(NULL)\n```\n\nКак видно, явная зависимость здесь не просматривается.\n\nТеперь при помощи другого вида графика посмотрим на наличие возможных статистических связей между признаками объектов. Можно сделать предварительные выводы, которые подтверждают мысли высказанные ранее. В частности, что шансы выжить уменьшаются с ростом класса и возраст - очень слабый признак для построения модели. Также можно обнаружить и другие закономерности. Между возрастом и классом существует отрицательная корреляция, что, скорее всего, связано с более возрастные пассажиры чаще могли себе позволить более дорогую каюту. Кроме того, стоимость билета и класс тесно связаны (высокий коэффициент корреляции), что вполне ожидаемо.\n```{r message=FALSE, warning=F}\nsource('my.plotcorr.R')\ncorplot_data <- data_train %>% \n        select(Survived, Pclass, Sex, Age, SibSp, Parch, Fare, Embarked) %>%\n        mutate(Survived = as.numeric(Survived), Pclass = as.numeric(Pclass),\n               Sex = as.numeric(Sex), Embarked = as.numeric(Embarked))\ncorr_train_data <- cor(corplot_data, use = \"na.or.complete\")\ncolsc <- c(rgb(241, 54, 23, maxColorValue=255), 'white', rgb(0, 61, 104, maxColorValue=255))\ncolramp <- colorRampPalette(colsc, space='Lab')\ncolorscor <-  colramp(100)\nmy.plotcorr(corr_train_data, col=colorscor[((corr_train_data + 1)/2) * 100],\n            upper.panel=\"number\", mar=c(1,2,1,1), main='Корреляция между признаками')\n\n\n```\n\nВернёмся к пропущенным значениям в данных. Один из обычных способов борьбы с ними - это замена на среднее от доступных значении того же признака. Например, 177 пропущенных из признака `Age` можно заменить на 29.7 \n```{r}\nsummary(data_train$Age)\n```\n\nТакой способ я уже успешно применял раннее с признаком `Embarked`, но там было всего две замены, а здесь же - 177, что составляет более 20% от всех имеющихся данных по этому признаку. Поэтому, стоит найти более точный способ замены.\n\nОдин из возможных вариантов - это взять среднее, но в зависимости от класса каюты, т.к., если посмотреть на график, расположенный ниже, то такая взаимосвязь возможно. И, если подумать, то такое предположение интуитивно понятно: чем старше человек - тем его вероятное благосостояние выше и, соответственно, выше и тот уровень комфорта, который он может себе позволить. Таким образом, можно заменить пропущенное значение для пассажира, например из третьего класса, средним возрастом для этого класса, что уже будет большим прогрессом, по сравнению с просто средним по всем пассажирам.\n```{r fig.width= 9, fig.height= 4, warning=F}\nggplot(data_train, aes(x = factor(Pclass, labels = c(\"Первый\", \"Второй\", \"Третий\")), \n                       y = Age, fill = factor(Pclass))) + \n        geom_boxplot() + scale_fill_manual (values=colours) + \n        ylab(\"Возраст\") + xlab(\"Класс каюты\") + guides(fill=FALSE)\n\n```\n\nНо давайте обратимся к другому из возможных вариантов замены пропущенных значений признака `Age`. Если посмотреть на значения признака `Name`, то можно заметить интересную особенность.\n```{r}\nhead(data_train$Name)\n```\n\nИмя каждого пассажира построено каждый раз по одному паттерну: \"Фамилия, [Гоноратив](https://goo.gl/1J9vnC). Имя\". Обращение `Master` в 19 веке применялость по отношению к детям мужского пола, соответственно, это можно использовать для выделения более узких и точных групп по возрасту. А `Miss` применялось по отношению к незамужним женщинам, но в 19 веке незамужними были, в подавляющем большинстве, только молодые девушки и девочки. Для того, чтобы использовать эту зависимость создадим новый признак `Title`.\n```{r warning=F, message=FALSE}\nrequire(stringr)\ndata_train$Title <-  data_train$Name %>% str_extract(., \"\\\\w+\\\\.\") %>% str_sub(.,1, -2)\nunique(data_train$Title)\n```\n\nТеперь определим титулы, среди владельцов которых есть хотя бы один с отсутствующим возрастом.\n```{r}\nmean_title <- data_train %>% group_by(Title) %>% \n        summarise(count = n(), Missing = sum(is.na(Age)), Mean = round(mean(Age, na.rm = T), 2))\nmean_title\n```\nИ проведём замену. Для этого создадим функцию и применим её к признаку `Age`. \n```{r}\nimpute.mean <- function (impute_col, filter_var, var_levels) {\n        for (lev in var_levels) { \n                impute_col[(filter_var == lev) & is.na(impute_col)] <-\n                        mean(impute_col[filter_var == lev], na.rm = T)\n        }\n        return (impute_col)\n}\ndata_train$Age <- impute.mean(data_train$Age, data_train$Title, c(\"Dr\", \"Master\", \"Mrs\", \"Miss\", \"Mr\"))\nsummary(data_train$Age)\n```\n\nЕсли обратить внимание на признак `Fare`(стоимость билета), то можно увидеть, что есть билеты с нулевой стоимостью.\n```{r}\nhead(table(data_train$Fare))\n```\n\nПервое объяснение, которое приходит в голову - это дети, но, если посмотреть на другие признаки этих пассажиров, то данное предположение оказывается ложным.\n```{r}\ndata_train %>% filter(Fare < 6) %>% select(Fare, Age, Pclass, Title) %>% arrange(Fare)\n```\n\nПоэтому, я думаю, что будет логично заменить нулевые значения на средние для класса, используя уже использовавшуюся функцию `impute.mean`.\n```{r}\ndata_train$Fare[data_train$Fare == 0] <- NA\ndata_train$Fare <- impute.mean(data_train$Fare, data_train$Pclass, as.numeric(levels(data_train$Pclass)))\n```\n\nПризнак `Title` введённый для замены пропущенных значений в признаке `Age` даёт нам дополнительную информацию о поле пассажира, его знатности (например `Don` и `Sir`) и приоритете в доступе к шлюпкам. Поэтому данный признак необходимо оставить и при построении модели. Всего у нас 17 значений данного признака. Следующий график показывает их взаимосвязь с возрастом.\n```{r fig.width= 9, fig.height= 4}\nggplot(data_train, aes(x = factor(Title, \n                                  c(\"Capt\",\"Col\",\"Major\",\"Sir\",\"Lady\",\"Rev\",\n                                   \"Dr\",\"Don\",\"Jonkheer\",\"Countess\",\"Mrs\", \n                                    \"Ms\",\"Mr\",\"Mme\",\"Mlle\",\"Miss\",\"Master\")), \n                       y = Age)) + geom_boxplot(fill= colours[3]) + guides(fill=FALSE) +\n        guides(fill=guide_legend(title=NULL)) + ylab(\"Возраст\") + xlab(NULL)\n\n```\n\nНо многие из значений, как я считаю, можно объединить в 5 групп: `Aristocratic`, `Mr`, `Mrs`, `Miss` и `Master`, т.к. объединяемые титулы принадлежать фактически одной или родственным группам. \n```{r fig.width= 9, fig.height= 4}\nchange.titles <- function(data, old_title, new_title) {\n  for (title in old_title) {\n    data$Title[data$Title == title] <- new_title\n  }\n  return (data$Title)\n}\ndata_train$Title <- change.titles(data_train, \n                               c(\"Capt\", \"Col\", \"Don\", \"Dr\", \n                               \"Jonkheer\", \"Lady\", \"Major\", \n                               \"Rev\", \"Sir\", \"Countess\"),\n                               \"Aristocratic\")\ndata_train$Title <- change.titles(data_train, c(\"Ms\"), \n                               \"Mrs\")\ndata_train$Title <- change.titles(data_train, c(\"Mlle\", \"Mme\"), \"Miss\")\ndata_train$Title <- as.factor(data_train$Title)\nggplot(data_train, aes(x = factor(Title, \n                                  c(\"Aristocratic\", \"Mrs\", \"Mr\", \"Miss\", \"Master\")), \n                       y = Age)) + geom_boxplot(fill= colours[3]) + guides(fill=FALSE) +\n        guides(fill=guide_legend(title=NULL)) + ylab(\"Возраст\") + xlab(NULL)\n```\n\nДавайте введём такой показатель как `Процент выживаемости` и посмотрим на его зависимость от групп, которые получились на предыдущем этапе.\n```{r fig.width= 9, fig.height= 4}\nSurv_rate_title <- data_train %>% group_by(Title) %>% \n        summarise(Rate = mean(as.numeric(as.character(Survived))))\nggplot(Surv_rate_title, aes(x = Title, y = Rate)) + \n        geom_bar(stat = \"identity\", width=.6, fill= colours[3]) +\n        xlab(NULL) + ylab(\"Процент выживаемости\")\n```\n\nДля того, чтобы получить составить хорошее представление о взаимосвязях между признаками лучше чем графика, как я думаю ничего ещё не придумано. Например, по следующему графику прикрасно видно, что основные группы выживших - это женщины первого и второго класса всех возрастов. А среди мужчин выжили все мальчики моложе 15 лет кроме третьего класса обслуживания и небольшая доля мужчин более старшего возраста и в основном из первого класса.\n\n```{r fig.width= 9, fig.height= 6}\nggplot(data = data_train, \n       aes(x = Age, y = Pclass, color = factor(Survived, labels = c(\"Погиб\", \"Выжил\")))) +\n        geom_point(shape = 1, size = 4, position=position_jitter(width=0.1,height=.1)) +\n        facet_grid(Sex ~ .) + guides(color=guide_legend(title=NULL)) +\n        xlab(\"Возраст\") + ylab(\"Класс каюты\")\n\n```\n\nТеперь посмотрим на информацию, которую можно получить из количества родственников на корабле.\n```{r fig.width= 9, fig.height= 4}\nggplot(data_train, aes(x = SibSp, y = Parch, \n                       color = factor(Survived, labels = c(\"Погиб\", \"Выжил\")))) + \n        geom_point(shape = 1, size = 4, \n                   position=position_jitter(width=0.3,height=.3)) +\n        guides(color=guide_legend(title=NULL)) + \n        xlab(\"Кол-во родственников\\n по горизонтали,\\n т.е. братья, сёстры\") + \n        ylab(\"Кол-во родственников\\n по вертикали,\\n т.е. родители, дети и т.д.\")\n\n```\nОчень похоже, что много родственников плохо и их отсутствие тоже.\n\nВведём такой признак как `Family`, т.е. количество родственников на борту корабля и посмотрим на влияние на выживаемость.\n```{r fig.width= 9, fig.height= 4}\nSurv_rate_family <- data_train %>% group_by(Family = SibSp + Parch) %>% \n        summarise(Rate = mean(as.numeric(as.character(Survived))))\nggplot(Surv_rate_family, aes(x = as.factor(Family), y = Rate)) + \n        geom_bar(stat = \"identity\", width=.6, fill= colours[3]) +\n        xlab(\"Кол-во родственников на борту корабля\") + ylab(\"Процент выживаемости\")\n\n```\nИ также в разрезе по полам пассажиров.\n```{r fig.width= 9, fig.height= 6}\ndata_train$Family <- data_train$SibSp + data_train$Parch\nggplot(data_train, aes(x = factor(Family), y = as.numeric(as.character(Survived)))) + \n        stat_summary( fun.y = mean, ymin=0, ymax=1, geom=\"bar\", size=4, fill= colours[2]) +\n        xlab(\"Кол-во родственников на борту корабля\") + ylab(\"Процент выживаемости\") + facet_grid(Sex ~ .)\n```\n\nНа графике видно, что для женщины небольшое количество родственников существенно повышает вероятность выжить. Статистическую значимость этой зависимости надо проверять, но, я думаю, что признак надо оставить и посмотреть на его влияние при создании модели. Так же, возможно, будет иметь смысл такой бинарный признак как \"Наличие родственников на борту\".\n```{r fig.width= 9, fig.height= 4}\ndata_train$isFamily <- as.factor(as.numeric(data_train$Family > 0))\nggplot( data_train, aes(x=factor(isFamily, labels =c(\"Нет\", \"Есть\")),y=as.numeric(as.character(Survived))) ) +\n        stat_summary( fun.y = mean, ymin=0, ymax=1, geom=\"bar\", size=4, fill= colours[2]) + \n        ylab(\"Процент выживаемости\") + xlab(\"Наличие родственников на борту корабля\")\n```\nНа первый взгляд, похоже, что присутствие родственников повышает вероятность выжить, но, если посмотреть на связь в разрезе по классам и полу, то картина меняется.\n```{r fig.width= 9, fig.height= 6}\nggplot(data_train, aes(x = factor(isFamily, labels =c(\"Нет\", \"Есть\")), y = as.numeric(as.character(Survived)))) +\n        stat_summary( fun.y = \"mean\", geom=\"bar\", ymin=0, ymax=1, fill= colours[2]) + \n        facet_grid(Pclass ~ Sex) + ylab(\"Процент выживаемости\") + xlab(\"Наличие родственников на борту корабля\")\n```\nДля мужчины во втором классе родственники повышают выживаемость, но для женщины в третьем классе - ситуация обратная.\n\nИз признака `Cabin`, т.е. номера каюты занимаемой пассажиром, можно было бы извлечь номер палубы (это буква в номере) и на каком борту была каюта (если последняя цифра номера нечётная, то это левый борт, и, соответственно, наоборот), но, т.к. номера кают в данных есть всего лишь у 20% пассажиров, то я не думаю, что это существенно повлияет на точность модели. Гораздо интереснее, по моему мнению, будет информация о наличии этого номера. Номера кают первого класса стали известны из списка, который был найден на теле стюарта [Herbert Cave](http://www.encyclopedia-titanica.org/cave-list.html), больше никакой официальной информации не сохранилось, соответственно, можно сделать вывод, что, если известен номер каюты пассажира второго или третьего класса, то он выжил. Поэтому, как и с родственниками, посмотрим на выживаемость в зависимости от наличия номера каюты в целом по всем пассажирам и в разрезе по классам и полу. \n\n```{r fig.width= 9, fig.height= 4}\ndata_train$isCabin <- factor(ifelse(is.na(data_train$Cabin),0,1))\nggplot( data_train, aes(x=factor(isCabin, labels =c(\"Нет\", \"Есть\")),y=as.numeric(as.character(Survived))) ) +\n        stat_summary( fun.y = mean, ymin=0, ymax=1, geom=\"bar\", size=4, fill= colours[3]) + \n        ylab(\"Процент выживаемости\") + xlab(\"Наличие номера каюты\")\nggplot(data_train, aes(x = factor(isCabin, labels =c(\"Нет\", \"Есть\")), y = as.numeric(as.character(Survived)))) +\n        stat_summary( fun.y = \"mean\", geom=\"bar\", ymin=0, ymax=1, fill= colours[3]) + \n        facet_grid(Pclass ~ Sex) + ylab(\"Процент выживаемости\") + xlab(\"Наличие номера каюты\")\n```\nОчевидно, что предположение подтвердилось, в особенности для пассажиров мужского пола.\n\nПодведём итог всей исследовательской работе, которая была проделана. \n\n- Были выявлены определённые закономерности в данных, но для того, чтобы точно сказать, что целевой признак зависит от этого и от этого необходимо провести статистический анализ.\n- Были созданы дополнительные признаки `Title`, `Family`, `isFamily`, `isCabin`, которые, на мой взгляд, оказывают влияние на целевой признак и могут быть использованы при создании модели. Но окончательный вывод о пользе этих признаков можно будет сделать только в процессе создания предсказательной модели.\n\nТеперь выделим из данных те признаки, которые будем использовать при создании модели.\n```{r}\ndata_train %<>% select(Survived, Pclass, Sex, Age, Fare, Embarked, Title, Family, isFamily, isCabin)\n```\n\nИ последний график в этой части работы.\n```{r}\ncorplot_data <- data_train %>% \n        select(Survived, Pclass, Sex, Age, Fare, Embarked, Family, isFamily, isCabin) %>%\n        mutate(Survived = as.numeric(Survived), Pclass = as.numeric(Pclass),\n               Sex = as.numeric(Sex), Embarked = as.numeric(Embarked),\n               isFamily = as.numeric(isFamily), isCabin = as.numeric(isCabin))\ncorr_train_data <- cor(corplot_data, use = \"na.or.complete\")\ncolsc <- c(rgb(241, 54, 23, maxColorValue=255), 'white', rgb(0, 61, 104, maxColorValue=255))\ncolramp <- colorRampPalette(colsc, space='Lab')\ncolorscor <-  colramp(100)\nmy.plotcorr(corr_train_data, col=colorscor[((corr_train_data + 1)/2) * 100],\n            upper.panel=\"number\", mar=c(1,2,1,1), main='Корреляция между признаками')\n```\n\n```{r message=FALSE, warning=F}\nrequire(plyr)\nrequire(dplyr)\ndata_train$Survived %<>% revalue(., c(\"0\"=\"Died\", \"1\" = \"Survived\"))\ndata_train$Pclass %<>% revalue(., c(\"1\"=\"First\", \"2\"=\"Second\", \"3\"=\"Third\"))\ndata_train$Sex %<>% revalue(., c(\"female\"=\"Female\", \"male\"=\"Male\"))\ndata_train$isFamily %<>% revalue(., c(\"0\"=\"No\", \"1\"=\"Yes\"))\ndata_train$isCabin %<>% revalue(., c(\"0\"=\"No\", \"1\"=\"Yes\"))\n```\n\n### Создание модели\n\nВ работе я буду использовать пакет `caret`, который вобрал в себя большинство из известных моделей машинного обучения и предоставляет удобный интерфейс для использования их на практике. Не смотря на то, что у нас есть тестовая выборка предоставляемая сайтом Kaggle, нам всё равно необходимо разбить тренировочную выборку на две части. На одной из которых мы будем тренировать модель, а на другой - оценивать её качество, прежде чем применять к соревновательной выборке. Я выбрал разделение в соотношении 80/20.\n```{r message=FALSE, warning=F}\nrequire(caret)\nset.seed(111)\nsplit <- createDataPartition(data_train$Survived, p = 0.8, list = FALSE)\ntrain <- slice(data_train, split)\ntest <- slice(data_train, -split)\n```\nНачнём с простейшей классификационной модели - логистической регрессии. Для оценки модели будем использовать статистику `residual deviance` или девианс остатков, который косвенно соответствует дисперсии в данных, оставшейся необъясненной после применения модели. `Null deviance` или нуль-девианс - это девианс \"пустой\" модели, не включающей ни одного параметра кроме beta0. Соответственно чем меньше девианс остатков по отношению к нуль-девианс - тем лучше модель. В дальнейшем, для сравнения различных моделей, будет применятся статистика `AUC` или площадь под кривой ROC. Для того, чтобы избежать переобучения моделей под этот параметр, будет использоваться десятикратная кросс-проверка(10-fold cross-validation (CV)) с разбиением выборки на 10 частей.\n\nИтак, первая модель - это логистическая регрессия. В качестве признаков выбраны изначально присутствующие в предоставленных данных предикторы.\n```{r message=FALSE, warning=F}\ncv_ctrl <- trainControl(method = \"repeatedcv\", repeats = 10,\n                        summaryFunction = twoClassSummary,\n                        classProbs = TRUE)\nset.seed(111)\nglm.tune.1 <- train(Survived ~ Pclass + Sex + Age + Fare + Embarked + Family,\n                    data = train,\n                    method = \"glm\",\n                    metric = \"ROC\",\n                    trControl = cv_ctrl)\nglm.tune.1\nsummary(glm.tune.1)\n```\nМодель уже показывает неплохие показатели в снижении девианса на 950-613=337 пунктов. Теперь попробуем улучшить этот показатель путём ввода тех новых признаков, которые были добавлены ранее.\n```{r message=FALSE, warning=F}\nset.seed(111)\nglm.tune.2 <- train(Survived ~ Pclass + Sex + Age + Fare + Embarked + Title + Family + isFamily + isCabin,\n                    data = train,\n                    method = \"glm\",\n                    metric = \"ROC\",\n                    trControl = cv_ctrl)\nglm.tune.2\nsummary(glm.tune.2)\n```\nПрекрасный результат! Ещё снижение на 613-566=47 пунктов. Но, я думаю, что можно улучшить модель, во-первых, убрав признак `Sex`, который стал избыточным, т.к. признак `Title` содержит в себе его информацию и даже больше. Также уберём признак `Fare`, т.к. он не является статистически значимым и только усложняет модель. Плюс изменим признак `Embarked` трансформировав его в двухуровневый.\n```{r message=FALSE, warning=F}\nset.seed(111)\nglm.tune.3 <- train(Survived ~ Pclass + Age + I(Embarked==\"S\") + Title + Family + isFamily + isCabin,\n                    data = train,\n                    method = \"glm\",\n                    metric = \"ROC\",\n                    trControl = cv_ctrl)\nglm.tune.3\nsummary(glm.tune.3)\n```\nУлучшения не произошло, даже, скорее, наоборот. Но мы продолжим удалять избыточные предикторы. Удалим `isFamily`, т.к. `Family` содержит в себе всю его информацию. И из классов оставим только третий, как наиболее значимый для модели. Аналогично поступим с `Title`.\n```{r message=FALSE, warning=F}\nset.seed(111)\nglm.tune.4 <- train(Survived ~ I(Pclass==\"Third\") +\n                                         Age +\n                                         I(Embarked==\"S\") + \n                                         I(Title==\"Master\") + \n                                         I(Title==\"Miss\") + \n                                         I(Title==\"Mrs\")  + \n                                         Family + \n                                         isCabin, \n                    data = train,\n                    method = \"glm\",\n                    metric = \"ROC\",\n                    trControl = cv_ctrl)\nglm.tune.4\nsummary(glm.tune.4)\n```\nТеперь выделим в отдельный признак мужчин из третьего класса, т.к., насколько я помню из анализа данных, именно они составляли основную долю погибших.\n```{r message=FALSE, warning=F}\nset.seed(111)\nglm.tune.5 <- train(Survived ~ Pclass +\n                            Age + \n                            I(Embarked==\"S\") + \n                            I(Title==\"Master\") + \n                            I(Title==\"Miss\") + \n                            I(Title==\"Mrs\")  + \n                            Family +\n                            isCabin +\n                            I(Title==\"Mr\"& Pclass==\"Third\"), \n                    data = train,\n                    method = \"glm\",\n                    metric = \"ROC\",\n                    trControl = cv_ctrl)\nglm.tune.5\nsummary(glm.tune.5)\n```\nИ мы получили существенный скачок в качестве модели. На данном этапе остановимся с логистической регрессией и обратимся к другим моделям.\nВ частности, к очень популярному `Random Forest`. При тренировки этой модели можно выбрать количество случайно выбираемых, для каждого из множества создаваемых деревьев, признаков - `mtry`.  \n```{r message=FALSE, warning=F}\nrf.grid <- data.frame(.mtry = c(2, 3, 4))\nset.seed(111)\nrf.tune <- train(Survived ~ Pclass + Sex + Age + Fare + Embarked + Title + Family + isFamily + isCabin, \n                 data = train,\n                 method = \"rf\",\n                 metric = \"ROC\",\n                 tuneGrid = rf.grid,\n                 trControl = cv_ctrl)\nrf.tune\n```\nВ данном случае, наилучшие показатели имеет модель с `mtry` равным 3.\n\nИ последняя модель, которая будет применена в данной работе - это support vector machine (SVM). SVM чувствительна к ненормализованным входным данным, поэтому будет использован параметр `preProcess`, чтобы перед тренировкой модели была проведена нормализация. У SVM в качестве одного из параметров используется `Cost`. Модель будет выполнена на его 9 различных значениях и выбрана с наилучшими показателями `AUC`.\n```{r message=FALSE, warning=F}\nset.seed(111)\nsvm.tune <- train(Survived ~ Pclass + Sex + Age + Fare + Embarked + Title + Family + isFamily + isCabin, \n                  data = train,\n                  method = \"svmRadial\",\n                  tuneLength = 9,\n                  preProcess = c(\"center\", \"scale\"),\n                  metric = \"ROC\",\n                  trControl = cv_ctrl)\nsvm.tune\nplot(svm.tune)\n```\n### Оценка модели.\nДля всех трёх созданных моделей проведём оценку при помощи пересечения предсказанных на тестовой выборке и реальных значений целевого признака. Функция `confusionMatrix` из пакета `Caret` позволяет легко это сделать.\n\n```{r message=FALSE, warning=F}\nglm.pred <- predict(glm.tune.4, test)\nconfusionMatrix(glm.pred, test$Survived)\n\nrf.pred <- predict(rf.tune, test)\nconfusionMatrix(rf.pred, test$Survived)\n\nsvm.pred <- predict(svm.tune, test)\nconfusionMatrix(svm.pred, test$Survived)\n```\n\nSVM и Random Forest показывают одинаковые лучшие результаты в предсказании выживших, a в предсказании погибших наилучшие показатели имеет Random Forest.\n\nИзобразим на одном графике кривые ROC на тестовых данных для всех созданых моделей.\n```{r message=FALSE, warning=F}\nrequire(pROC)\nglm.probs <- predict(glm.tune.5, test, type = \"prob\")\nglm.ROC <- roc(response = test$Survived,\n                predictor = glm.probs$Survived,\n                levels = levels(test$Survived))\nglm.ROC$auc\nplot(glm.ROC, type=\"S\")\n\nrf.probs <- predict(rf.tune, test, type = \"prob\")\nrf.ROC <- roc(response = test$Survived,\n           predictor = rf.probs$Survived,\n           levels = levels(test$Survived))\nrf.ROC$auc\nplot(rf.ROC, add=TRUE, col=\"red\")\n\n\nsvm.probs <- predict(svm.tune, test, type = \"prob\")\nsvm.ROC <- roc(response = test$Survived,\n            predictor = svm.probs$Survived,\n            levels = levels(test$Survived))\nsvm.ROC$auc\nplot(svm.ROC, add=TRUE, col=\"blue\")\n```\nПо статистике `AUC` лидирует Random Forest, но это результаты однократного применения модели на тестовой выборке. Если же собрать эту статистику путём resampling, то результат будет другим, что и показано на следующем графике.\n```{r message=FALSE, warning=F}\nresamps <- resamples(list(Logit = glm.tune.5, RF = rf.tune, SVM = svm.tune))\nsummary(resamps)\ndotplot(resamps, metric = \"ROC\")\n```\n\nИ, наконец, последний график этой работы. Это суммарная информация по моделям по трём статистикам:`ROC`,`Sensitivity` и `Specificity`.\n```{r}\nbwplot(resamps, layout = c(3, 1))\n```\nМожно сделать вывод, что все три модели лучше предсказывают погибших чем выживших(соответственно статистики `Sensitivity` и `Specificity`). Но, в целом, статистические результаты моделей не отличаются друг от друга. Но, с точки зрения простоты модели и обобщающих свойств, я считаю, что наилучшие результаты на новой неизвестной выборке в среднем должна показывать логистическая регрессия.\n\n### Использование результатов для Kaggle\n\nСледующий блок кода пременяет выбранную модель на оценочных данных и создаёт файл для загрузки на сайт.\n\n```{r eval=FALSE}\ndata_test$Cabin <- recode(data_test$Cabin, \"'' = NA\")\ndata_test$Embarked <- recode(data_test$Embarked, \"'' = NA\")\ndata_test %<>% transform(.,Pclass = as.factor(Pclass), \n                          Sex = as.factor(Sex),\n                          Embarked = as.factor(Embarked),\n                          SibSp = as.numeric(SibSp))\ndata_test$Embarked[is.na(data_test$Embarked)] <- \"S\"\ndata_test$Title <-  data_test$Name %>% str_extract(., \"\\\\w+\\\\.\") %>% str_sub(.,1, -2)\n\n\ndata_test %>% group_by(Title) %>% \n        summarise(count = n(), Missing = sum(is.na(Age)), Mean = round(mean(Age, na.rm = T), 2))\nimpute.mean.test <- function (impute_col, filter_var, var_levels) {\n        for (lev in var_levels) { \n                impute_col[(filter_var == lev) & is.na(impute_col)] <-\n                        mean_title$Mean[mean_title$Title == lev]\n                        #mean(impute_col[filter_var == lev], na.rm = T)\n        }\n        return (impute_col)\n}\ndata_test$Age <- impute.mean.test(data_test$Age, data_test$Title, c(\"Ms\", \"Master\", \"Mrs\", \"Miss\", \"Mr\"))\n\ndata_test$Fare[data_test$Fare == 0] <- NA\ndata_test$Fare <- impute.mean(data_test$Fare, data_test$Pclass, as.numeric(levels(data_test$Pclass)))\ndata_test$Title <- change.titles(data_test, \n                                  c(\"Capt\", \"Col\", \"Don\", \"Dr\", \n                                   \"Jonkheer\", \"Lady\", \"Major\", \n                                    \"Rev\", \"Sir\", \"Countess\", \"Dona\"),\n                                  \"Aristocratic\")\ndata_test$Title <- change.titles(data_test, c(\"Ms\"), \n                                  \"Mrs\")\ndata_test$Title <- change.titles(data_test, c(\"Mlle\", \"Mme\"), \"Miss\")\ndata_test$Title <- as.factor(data_test$Title)\n\ndata_test$Family <- data_test$SibSp + data_test$Parch\ndata_test$isFamily <- as.factor(as.numeric(data_test$Family > 0))\ndata_test$isCabin <- factor(ifelse(is.na(data_test$Cabin),0,1))\ndata_test %<>% select(PassengerId, Pclass, Sex, Age, Fare, Embarked, Title, Family, isFamily, isCabin)\ndata_test$Pclass %<>% revalue(., c(\"1\"=\"First\", \"2\"=\"Second\", \"3\"=\"Third\"))\ndata_test$Sex %<>% revalue(., c(\"female\"=\"Female\", \"male\"=\"Male\"))\ndata_test$isFamily %<>% revalue(., c(\"0\"=\"No\", \"1\"=\"Yes\"))\ndata_test$isCabin %<>% revalue(., c(\"0\"=\"No\", \"1\"=\"Yes\"))\n\nSurvived <- predict(svm.tune, newdata = data_test)\nSurvived <- revalue(Survived, c(\"Survived\" = 1, \"Died\" = 0))\npredictions <- as.data.frame(Survived)\npredictions$PassengerId <- data_test$PassengerId\nwrite.csv(predictions[,c(\"PassengerId\", \"Survived\")], \n          file=\"Titanic_predictions.csv\", row.names=FALSE, quote=FALSE)\n```\nПосле загрузки результатов применения моделей на Kaggle наилучшие результаты показала модель SVM. Входя на момент написания этой работы в лучшие 10% результатов, но, т.к. до окончания соревнования модель оценивается только по части данных, то финальные результаты могут сильно отличаться, причём как в лучшую, так и в худшую сторону.\n",
    "created" : 1439585457976.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2208367656",
    "id" : "81CDF6AE",
    "lastKnownWriteTime" : 1439625850,
    "path" : "G:/R lang/Titanic/Titanic.Rmd",
    "project_path" : "Titanic.Rmd",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 4,
    "source_on_save" : false,
    "type" : "r_markdown"
}